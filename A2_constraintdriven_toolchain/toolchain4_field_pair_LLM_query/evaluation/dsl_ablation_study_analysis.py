#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Analyze Generated DSL Rules - Evidence Category Analysis (FIXED)
Fix 1: Correctly identify all cross-doc evidence (including TS 38.211)
Fix 2: Exclude summary.json to match token calculation (1482 files)
Simplified version: Output statistical data only
"""

import json
import os
import glob
from collections import defaultdict
from datetime import datetime

# ============================================================================
# Configuration
# ============================================================================

DEFAULT_DSL_DIR = "../intra-IE/outputs/intra-IE_DSL_results_gpt4o"

# ============================================================================
# DSL Analysis Functions
# ============================================================================

def load_dsl_files(dsl_dir):
    """Load all DSL JSON files (recursively), excluding summary.json"""
    print(f"Loading DSL files from: {dsl_dir}")
    all_files = glob.glob(os.path.join(dsl_dir, "**", "*.json"), recursive=True)
    
    # ÊéíÈô§ summary.json Êñá‰ª∂Ôºà‰∏é token calculation ‰øùÊåÅ‰∏ÄËá¥Ôºâ
    dsl_files = [f for f in all_files if os.path.basename(f) != 'summary.json']
    
    print(f"  Found {len(dsl_files)} DSL files (excluding summary.json)")
    return dsl_files

def categorize_evidence_sources(all_sources, evidence_count):
    """
    Categorize evidence sources - FIXED VERSION
    
    Args:
    - all_sources: List of source files
    - evidence_count: Number of evidences
    
    Returns:
    - has_ts_331: True if has TS 38.331 evidence
    - has_cross_doc: True if has TS 38.2xx evidence
    - evidence_category: 'full', 'no_crossdoc', or 'asn1_only'
    """
    # If no evidence at all, it's ASN.1-only
    if not all_sources or evidence_count == 0:
        return False, False, 'asn1_only'
    
    has_ts_331 = False
    has_cross_doc = False
    
    for source in all_sources:
        source_lower = source.lower()
        
        # TS 38.331 (RRC specification - main spec)
        if 'ts_138331' in source_lower or 'ts138331' in source_lower:
            has_ts_331 = True
        
        # Cross-document evidence (all TS 38.2xx specs)
        if any(doc in source_lower for doc in [
            'ts_138211', 'ts138211',  # Physical layer channels
            'ts_138213', 'ts138213',  # Physical layer procedures for data
            'ts_138214', 'ts138214',  # Physical layer procedures
            'ts_138321', 'ts138321',  # MAC protocol
            'ts_138322', 'ts138322',  # RLC protocol
        ]):
            has_cross_doc = True
    
    # Determine category
    if has_ts_331 and has_cross_doc:
        evidence_category = 'full'
    elif has_ts_331 and not has_cross_doc:
        evidence_category = 'no_crossdoc'
    elif not has_ts_331 and has_cross_doc:
        # Cross-doc only (without TS 38.331) - still "full"
        evidence_category = 'full'
    else:
        # Has evidence but not from known specs
        evidence_category = 'full'
    
    return has_ts_331, has_cross_doc, evidence_category

def analyze_dsl_file(dsl_file):
    """Analyze a single DSL file"""
    try:
        with open(dsl_file, 'r', encoding='utf-8') as f:
            dsl_data = json.load(f)
        
        has_valid_rule = dsl_data.get('has_valid_rule', False)
        
        meta = dsl_data.get('meta', {})
        ie_name = meta.get('ie_name', 'unknown')
        field1 = meta.get('field1', 'unknown')
        field2 = meta.get('field2', 'unknown')
        all_sources = meta.get('all_sources', [])
        evidence_info = meta.get('evidence_info', {})
        evidence_count = evidence_info.get('used_count', 0)
        best_confidence = meta.get('best_confidence', 'UNKNOWN')
        
        # Categorize evidence (pass evidence_count!)
        has_ts_331, has_cross_doc, evidence_category = categorize_evidence_sources(
            all_sources, evidence_count
        )
        
        return {
            'filename': os.path.basename(dsl_file),
            'has_valid_rule': has_valid_rule,
            'ie_name': ie_name,
            'field1': field1,
            'field2': field2,
            'all_sources': all_sources,
            'has_ts_331': has_ts_331,
            'has_cross_doc': has_cross_doc,
            'evidence_category': evidence_category,
            'evidence_count': evidence_count,
            'best_confidence': best_confidence,
            'dsl_rule': dsl_data.get('dsl_rule', '')
        }
    
    except Exception as e:
        print(f"  Error processing {dsl_file}: {e}")
        return None

def analyze_all_dsl_files(dsl_files):
    """Analyze all DSL files"""
    print(f"\n{'='*60}")
    print("Analyzing DSL Files")
    print(f"{'='*60}")
    
    results = []
    for idx, dsl_file in enumerate(dsl_files, 1):
        if idx % 100 == 0:
            print(f"  Processed {idx}/{len(dsl_files)} files...")
        
        result = analyze_dsl_file(dsl_file)
        if result:
            results.append(result)
    
    print(f"\n‚úÖ Analyzed {len(results)} DSL files")
    return results

# ============================================================================
# Statistical Analysis
# ============================================================================

def calculate_evidence_category_stats(results):
    """Calculate statistics by evidence category"""
    print(f"\n{'='*60}")
    print("Calculating Evidence Category Statistics")
    print(f"{'='*60}")
    
    # Group by category
    category_groups = {
        'full': [r for r in results if r['evidence_category'] == 'full'],
        'no_crossdoc': [r for r in results if r['evidence_category'] == 'no_crossdoc'],
        'asn1_only': [r for r in results if r['evidence_category'] == 'asn1_only']
    }
    
    # Calculate stats for each category
    stats = {}
    for category, pairs in category_groups.items():
        valid_count = sum(1 for r in pairs if r['has_valid_rule'])
        total_count = len(pairs)
        
        stats[category] = {
            'total': total_count,
            'valid': valid_count,
            'rate': valid_count / total_count if total_count > 0 else 0,
            'percentage': (valid_count / total_count * 100) if total_count > 0 else 0,
            'pairs': [r['filename'] for r in pairs if r['has_valid_rule']]
        }
    
    # Print distribution
    print(f"\nüìä Evidence Category Distribution:")
    print(f"  Full (with cross-doc): {stats['full']['total']} pairs")
    print(f"  No CrossDocs (TS 38.331 only): {stats['no_crossdoc']['total']} pairs")
    print(f"  ASN.1-only (no evidence): {stats['asn1_only']['total']} pairs")
    print(f"  Total: {sum(s['total'] for s in stats.values())} pairs")
    
    print(f"\n‚úÖ Valid Rules by Category:")
    for category, stat in stats.items():
        category_name = {
            'full': 'Full (with cross-doc)',
            'no_crossdoc': 'No CrossDocs',
            'asn1_only': 'ASN.1-only'
        }[category]
        print(f"  {category_name}: {stat['valid']}/{stat['total']} ({stat['percentage']:.1f}%)")
    
    return stats

def print_results(stats):
    """Print detailed results"""
    print(f"\n{'='*60}")
    print("EVIDENCE CATEGORY ANALYSIS RESULTS")
    print(f"{'='*60}")
    
    full = stats['full']
    no_cross = stats['no_crossdoc']
    asn1 = stats['asn1_only']
    
    total_pairs = full['total'] + no_cross['total'] + asn1['total']
    total_valid = full['valid'] + no_cross['valid'] + asn1['valid']
    
    print(f"\nTotal field pairs evaluated: {total_pairs}")
    print(f"Total valid rules generated: {total_valid} ({total_valid/total_pairs*100:.1f}%)")
    
    print(f"\n{'Evidence Category':<30} {'Pairs':<15} {'Valid Rules':<15} {'Success Rate':<15}")
    print(f"{'-'*75}")
    print(f"{'Full Evidence (cross-doc)':<30} {full['total']:<15} {full['valid']:<15} {full['percentage']:>6.1f}%")
    print(f"{'No CrossDocs (TS 38.331 only)':<30} {no_cross['total']:<15} {no_cross['valid']:<15} {no_cross['percentage']:>6.1f}%")
    print(f"{'ASN.1-only (no evidence)':<30} {asn1['total']:<15} {asn1['valid']:<15} {asn1['percentage']:>6.1f}%")
    
    # Key Findings
    print(f"\n{'='*60}")
    print("Key Findings")
    print(f"{'='*60}")
    
    print(f"\n1. Cross-Document Evidence Impact:")
    print(f"   - {full['valid']} rules generated from {full['total']} pairs with cross-doc evidence")
    print(f"   - {no_cross['valid']} rules from {no_cross['total']} pairs with only TS 38.331")
    print(f"   - Absolute difference: {full['valid'] - no_cross['valid']} rules")
    print(f"   - {full['valid']} of {total_valid} total rules ({full['valid']/total_valid*100:.1f}%) came from cross-doc")
    
    print(f"\n2. ASN.1-only Limitation:")
    print(f"   - {asn1['valid']}/{asn1['total']} pairs ({asn1['percentage']:.1f}%) with no evidence generated rules")
    if asn1['valid'] == 0:
        print(f"   - Confirms that textual evidence is necessary (citation gate working)")
    else:
        print(f"   - WARNING: {asn1['valid']} rules without evidence (possible validation issue)")

def analyze_confidence_distribution(results):
    """Analyze confidence distribution"""
    print(f"\n{'='*60}")
    print("Confidence Distribution")
    print(f"{'='*60}")
    
    confidence_stats = defaultdict(lambda: {'total': 0, 'valid': 0})
    
    for result in results:
        conf = result['best_confidence']
        confidence_stats[conf]['total'] += 1
        if result['has_valid_rule']:
            confidence_stats[conf]['valid'] += 1
    
    print(f"\n{'Confidence':<15} {'Total':<10} {'Valid':<10} {'Success Rate':<15}")
    print(f"{'-'*50}")
    
    for conf in ['HIGH', 'MEDIUM', 'LOW', 'VERY_LOW', 'UNKNOWN']:
        if conf in confidence_stats:
            stats = confidence_stats[conf]
            success_rate = stats['valid'] / stats['total'] * 100 if stats['total'] > 0 else 0
            print(f"{conf:<15} {stats['total']:<10} {stats['valid']:<10} {success_rate:>6.1f}%")

def save_detailed_results(stats, results, output_file):
    """Save detailed results to JSON"""
    output = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'total_pairs': sum(s['total'] for s in stats.values()),
            'description': 'Fixed evidence category analysis (includes TS 38.211, excludes summary.json)'
        },
        'category_stats': stats,
        'detailed_results': results
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, indent=2, ensure_ascii=False)
    
    print(f"\nüíæ Detailed results saved to: {output_file}")

# ============================================================================
# Main Function
# ============================================================================

def main():
    import argparse
    
    parser = argparse.ArgumentParser(
        description='Analyze DSL Rules - Evidence Category Analysis (FIXED)'
    )
    parser.add_argument('--dsl_dir', default=DEFAULT_DSL_DIR,
                       help='Directory containing DSL JSON files')
    parser.add_argument('--output_dir', default='./dsl_evidence_analysis_fixed',
                       help='Output directory')
    
    args = parser.parse_args()
    
    print("="*60)
    print("üî¨ DSL EVIDENCE CATEGORY ANALYSIS (FIXED)")
    print("="*60)
    print(f"DSL directory: {args.dsl_dir}")
    print(f"Output directory: {args.output_dir}")
    print(f"\nFIXES APPLIED:")
    print(f"  1. Correctly identifies all cross-doc evidence")
    print(f"     (including TS 38.211, 38.213, 38.214, 38.321, 38.322)")
    print(f"  2. Excludes summary.json (matches token calculation: 1482 files)")
    
    os.makedirs(args.output_dir, exist_ok=True)
    
    # Load and analyze
    dsl_files = load_dsl_files(args.dsl_dir)
    if not dsl_files:
        print("\n‚ùå No DSL files found!")
        return
    
    results = analyze_all_dsl_files(dsl_files)
    if not results:
        print("\n‚ùå No valid results!")
        return
    
    # Calculate stats
    stats = calculate_evidence_category_stats(results)
    
    # Print results
    print_results(stats)
    analyze_confidence_distribution(results)
    
    # Save detailed results only
    results_file = os.path.join(args.output_dir, 'evidence_category_results.json')
    save_detailed_results(stats, results, results_file)
    
    print(f"\n{'='*60}")
    print("‚úÖ ANALYSIS COMPLETE!")
    print(f"{'='*60}")
    print(f"\nResults saved to: {args.output_dir}")
    print(f"Files analyzed: {len(results)} (matches token calculation)")

if __name__ == "__main__":
    main()